{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "740e2133",
   "metadata": {},
   "source": [
    "# Quantum Entropy (QUE) – Results Replication Notebook (Authors' Code Only)\n",
    "\n",
    "This notebook **reuses the original authors' scripts** to replicate the experiments discussed in the paper's results section (synthetic data, InternetAds, etc.).  \n",
    "We **do not implement new logic** here—only import and call functions from the repo's scripts.\n",
    "\n",
    "> Repo files expected in the working directory: `mean.py`, `utils.py`, `baselines.py`, `ads.py`, `data.py`, `part_utils.py`, `pixel.py`, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78be7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only the authors' code (imports from their scripts)\n",
    "import sys, os\n",
    "sys.path.append('.')  # ensure current dir is on path\n",
    "\n",
    "from utils import parse_args\n",
    "import mean  # main experiment driver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d5c4d",
   "metadata": {},
   "source": [
    "## Synthetic Data – Varying $\\alpha$ (QUE vs baselines)\n",
    "\n",
    "This cell runs the authors' synthetic experiment that varies the QUE parameter (alpha).  \n",
    "It uses functions and defaults defined by the authors in `utils.py` and `mean.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa04272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse default args from authors' parser, then select synthetic experiment\n",
    "opt = parse_args()\n",
    "opt.experiment_type = 'syn_lamb'   # authors' option\n",
    "opt.generate_data = True           # synthetic\n",
    "opt.use_std = True\n",
    "opt.compute_scores_diff = True\n",
    "opt.visualize_scores = False\n",
    "opt.whiten = True                  # as in paper, QUE benefits from whitening\n",
    "opt.rme = False                    # outlier detection, not robust mean here\n",
    "\n",
    "# This function is defined in mean.py and orchestrates the synthetic experiment:\n",
    "# It will generate data and compute ROCAUC for QUE and baselines as a function of alpha.\n",
    "# (Authors' function; we are only calling it.)\n",
    "mean.generate_and_score_lamb(opt, 'syn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a27bad",
   "metadata": {},
   "source": [
    "## InternetAds (tabular) Experiment\n",
    "\n",
    "This cell reproduces the InternetAds experiment using the authors' function `test_ads_data` in `mean.py`.  \n",
    "Ensure the InternetAds data file is available in the expected path (per `data.py`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada02648",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = parse_args()\n",
    "opt.experiment_type = 'ads'      # authors' selector for the InternetAds pipeline\n",
    "opt.generate_data = False        # not synthetic\n",
    "opt.use_std = True\n",
    "opt.compute_scores_diff = False\n",
    "opt.visualize_scores = False\n",
    "opt.whiten = False               # to match the paper's reported setup on InternetAds\n",
    "\n",
    "# Run the InternetAds evaluation (authors' code).\n",
    "mean.test_ads_data(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab57751",
   "metadata": {},
   "source": [
    "## Word Embeddings (GloVe) Experiments\n",
    "\n",
    "The following cells invoke the authors' GloVe experiments. You need to place the GloVe files under `data/` as expected by the repo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae778c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha sweep on text (authors' function). Requires GloVe under data/.\n",
    "opt = parse_args()\n",
    "opt.experiment_type = 'text_lamb'  # authors' option\n",
    "opt.generate_data = False\n",
    "opt.use_std = True\n",
    "opt.compute_scores_diff = True\n",
    "opt.visualize_scores = False\n",
    "opt.whiten = True\n",
    "mean.test_glove_data_lamb(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac62818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary number of outlier directions on text (authors' function). Requires GloVe under data/.\n",
    "opt = parse_args()\n",
    "opt.experiment_type = 'text_dirs'  # authors' option\n",
    "opt.generate_data = False\n",
    "opt.use_std = True\n",
    "opt.compute_scores_diff = False\n",
    "opt.visualize_scores = False\n",
    "opt.whiten = True\n",
    "mean.test_glove_data_dirs(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e2080",
   "metadata": {},
   "source": [
    "## CIFAR-10 \"Hot Pixels\" Experiment (Optional)\n",
    "\n",
    "The image experiment is driven by `pixel.py` in the repo. If the CIFAR data are present under `data/`, you can run the authors' image experiment by executing the module directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b436c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If data are present, this mirrors the authors' command-line entry:\n",
    "# (Uncomment to run in your environment.)\n",
    "# import runpy\n",
    "# import sys\n",
    "# sys.argv = ['pixel.py', '--experiment_type', 'image_lamb']\n",
    "# runpy.run_path('pixel.py', run_name='__main__')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bff3698",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "- All computations, score definitions, baselines, and plotting are implemented **by the authors**.  \n",
    "- This notebook merely **invokes** their functions to replicate the reported experiments.\n",
    "- For additional runtime flags, see `python mean.py -h` per the repo README.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
